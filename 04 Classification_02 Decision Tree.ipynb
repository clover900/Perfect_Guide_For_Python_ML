{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndt_clf = DecisionTreeClassifier(random_state=156)\n\niris_data = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n                                                    test_size=0.2, random_state=11)\n\ndt_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\n\nexport_graphviz(dt_clf, out_file=\"tree.dot\", class_names=iris_data.target_names, \n                feature_names= iris_data.feature_names, impurity=True, filled = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz\nwith open(\"tree.dot\") as f:\n    dot_graph = f.read()\ngraphviz.Source(dot_graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport numpy as np\n%matplotlib inline\n\n\nprint(\"Feature importances:\\n{0}\".format(np.round(dt_clf.feature_importances_, 3)))\n\nfor name, value in zip(iris_data.feature_names, dt_clf.feature_importances_):\n    print('{0}: {1:.3f}'.format(name, value))\n    \nsns.barplot(x=dt_clf.feature_importances_, y=iris_data.feature_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\n\nplt.title(\"3 Class values with 2 Features Sample data creation\")\n\nX_features, y_labels = make_classification(n_features=2, n_redundant=0, n_informative=2,\n                                           n_classes=3, n_clusters_per_class=1, random_state=0)\nplt.scatter(X_features[:, 0], X_features[:, 1], marker='o', c=y_labels, s=25, edgecolor='k')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n# Classifier의 Decision Boundary를 시각화 하는 함수\ndef visualize_boundary(model, X, y):\n    fig,ax = plt.subplots()\n    \n    # 학습 데이타 scatter plot으로 나타내기\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='rainbow', edgecolor='k',\n               clim=(y.min(), y.max()), zorder=3)\n    ax.axis('tight')\n    ax.axis('off')\n    xlim_start , xlim_end = ax.get_xlim()\n    ylim_start , ylim_end = ax.get_ylim()\n    \n    # 호출 파라미터로 들어온 training 데이타로 model 학습 . \n    model.fit(X, y)\n    # meshgrid 형태인 모든 좌표값으로 예측 수행. \n    xx, yy = np.meshgrid(np.linspace(xlim_start,xlim_end, num=200),np.linspace(ylim_start,ylim_end, num=200))\n    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n    \n    # contourf() 를 이용하여 class boundary 를 visualization 수행. \n    n_classes = len(np.unique(y))\n    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n                           levels=np.arange(n_classes + 1) - 0.5,\n                           cmap='rainbow', clim=(y.min(), y.max()),\n                           zorder=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# 특정한 트리 생성 제약없는 결정 트리의 Decsion Boundary 시각화.\ndt_clf = DecisionTreeClassifier().fit(X_features, y_labels)\nvisualize_boundary(dt_clf, X_features, y_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# min_samples_leaf=6 으로 트리 생성 조건을 제약한 Decision Boundary 시각화\ndt_clf = DecisionTreeClassifier( min_samples_leaf=6).fit(X_features, y_labels)\nvisualize_boundary(dt_clf, X_features, y_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# features.txt 파일에는 피처 이름 index와 피처명이 공백으로 분리되어 있음. 이를 DataFrame으로 로드.\nfeature_name_df = pd.read_csv('../input/human-activity/human_activity/features.txt',sep='\\s+',\n                        header=None,names=['column_index','column_name'])\n\n# 피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출\nfeature_name = feature_name_df.iloc[:, 1].values.tolist()\nprint('전체 피처명에서 10개만 추출:', feature_name[:10])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_dup_df = feature_name_df.groupby('column_name').count()\nprint(feature_dup_df[feature_dup_df['column_index']>1].count())\nfeature_dup_df[feature_dup_df['column_index']>1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_new_feature_name_df(old_feature_name_df):\n    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n                                  columns=['dup_cnt'])\n    feature_dup_df = feature_dup_df.reset_index()\n    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n                                                                                         if x[1] >0 else x[0] ,  axis=1)\n    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n    return new_feature_name_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndef get_human_dataset( ):\n    feature_name_df = pd.read_csv('../input/human-activity/human_activity/features.txt',sep='\\s+',\n                        header=None,names=['column_index','column_name'])\n\n    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n    X_train = pd.read_csv('../input/human-activity/human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n    X_test = pd.read_csv('../input/human-activity/human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n    y_train = pd.read_csv('../input/human-activity/human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n    y_test = pd.read_csv('../input/human-activity/human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n\n    return X_train, X_test, y_train, y_test\n\n\nX_train, X_test, y_train, y_test = get_human_dataset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('##학습 피처 데이터셋info()')\nprint(X_train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train['action'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ndt_clf = DecisionTreeClassifier(random_state=156)\ndt_clf.fit(X_train, y_train)\npred=dt_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\nprint('결정 트리 예측 정확도: {0:.4f}'.format(accuracy))\n\nprint('DecisionTreeClassifier 기본 하이퍼 파라미터:\\n', dt_clf.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparams = {\n    'max_depth' : [ 6, 8 ,10, 12, 16 ,20, 24]\n}\n\ngrid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\ngrid_cv.fit(X_train , y_train)\nprint('GridSearchCV 최고 평균 정확도 수치:{0:.4f}'.format(grid_cv.best_score_))\nprint('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ncv_results_df = pd.DataFrame(grid_cv.cv_results_)\ncv_results_df[['param_max_depth', 'mean_test_score']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_depths = [6,]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}